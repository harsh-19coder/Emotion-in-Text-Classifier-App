{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3ca1f97-afe2-4071-acbd-a74688c75634",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.61\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.64      0.54      0.59       836\n",
      "     disgust       0.86      0.09      0.16       202\n",
      "        fear       0.76      0.64      0.70      1104\n",
      "         joy       0.56      0.82      0.67      2214\n",
      "     neutral       0.69      0.33      0.45       481\n",
      "     sadness       0.57      0.57      0.57      1327\n",
      "       shame       0.75      0.39      0.51        23\n",
      "    surprise       0.62      0.40      0.48       772\n",
      "\n",
      "    accuracy                           0.61      6959\n",
      "   macro avg       0.68      0.47      0.52      6959\n",
      "weighted avg       0.63      0.61      0.59      6959\n",
      "\n",
      "\n",
      "Model and vectorizer saved successfully!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your message:  I am worried about what is going to happen tonight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted Emotion: fear\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "# Load Dataset (Ensure your CSV file has 'Text' and 'Emotion' columns)\n",
    "df = pd.read_csv(\"emotion_data.csv\")\n",
    "\n",
    "# Text Preprocessing Function\n",
    "def preprocess_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\W+\", \" \", text)  # Remove special characters\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words and word.isalnum()]\n",
    "    \n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Apply Preprocessing\n",
    "df[\"Clean_Text\"] = df[\"Text\"].astype(str).apply(preprocess_text)\n",
    "\n",
    "# Split Data into Training and Testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"Clean_Text\"], df[\"Emotion\"], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert Text to TF-IDF Features\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression Model\n",
    "log_reg = LogisticRegression(max_iter=500, solver=\"liblinear\")\n",
    "log_reg.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Evaluate the Model\n",
    "y_pred = log_reg.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")  # Expecting ~80% accuracy\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Save Model and Vectorizer for Future Use\n",
    "with open(\"logistic_regression_model.pkl\", \"wb\") as model_file:\n",
    "    pickle.dump(log_reg, model_file)\n",
    "\n",
    "with open(\"tfidf_vectorizer.pkl\", \"wb\") as vectorizer_file:\n",
    "    pickle.dump(vectorizer, vectorizer_file)\n",
    "\n",
    "print(\"\\nModel and vectorizer saved successfully!\")\n",
    "\n",
    "# ------------------------------ #\n",
    "# ðŸ“Œ User Input for Emotion Detection #\n",
    "# ------------------------------ #\n",
    "\n",
    "# Load Saved Model and Vectorizer\n",
    "with open(\"logistic_regression_model.pkl\", \"rb\") as model_file:\n",
    "    log_reg = pickle.load(model_file)\n",
    "\n",
    "with open(\"tfidf_vectorizer.pkl\", \"rb\") as vectorizer_file:\n",
    "    vectorizer = pickle.load(vectorizer_file)\n",
    "\n",
    "# Get User Input for Message\n",
    "user_message = input(\"\\nEnter your message: \")\n",
    "\n",
    "# Process and Predict Emotion\n",
    "processed_message = preprocess_text(user_message)\n",
    "message_vector = vectorizer.transform([processed_message])\n",
    "predicted_emotion = log_reg.predict(message_vector)[0]\n",
    "\n",
    "# Display Result\n",
    "print(f\"\\nPredicted Emotion: {predicted_emotion}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "395a71ab-dccb-4458-a6bd-79faf052c854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your message:  do u mind if i ask you a question\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted Emotion: fear\n"
     ]
    }
   ],
   "source": [
    "user_message = input(\"\\nEnter your message: \")\n",
    "\n",
    "# Process and Predict Emotion\n",
    "processed_message = preprocess_text(user_message)\n",
    "message_vector = vectorizer.transform([processed_message])\n",
    "predicted_emotion = log_reg.predict(message_vector)[0]\n",
    "\n",
    "# Display Result\n",
    "print(f\"\\nPredicted Emotion: {predicted_emotion}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff34094-8ef6-4c1b-9608-539cc04295bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671fb610-9076-4e5c-8a8e-82f59c287f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_project)",
   "language": "python",
   "name": "nltk_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
